{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist_clustering.ipynb","provenance":[{"file_id":"1nTi37NpHcbEPy0-ynqDQtgVJn5NHJ9Km","timestamp":1633281052010}],"collapsed_sections":[],"authorship_tag":"ABX9TyNGrEpfUpsY1ntkunwIjy0V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HOGRjif9-O__"},"source":["# Clustering on MNIST Dataset\n","In this exercise, you will finish working with the MNIST dataset, using clustering algorithms to attempt to recreate the clusters. \n","\n","Your task is to implement an algorithm that clusters handwritten digits, and evaluate how well this reconstructs the true groupings (by actual labeled value). \n","\n","Read more about this dataset [here](https://en.wikipedia.org/wiki/MNIST_database)"]},{"cell_type":"code","metadata":{"id":"mPOCmVqB-Jil"},"source":["# Run this, no changes required \n","from sklearn import datasets\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()\n","\n","#Load the digits dataset\n","digits = datasets.load_digits()\n","\n","#Display the first digit\n","print(digits.target[0])\n","plt.figure(1, figsize=(3, 3))\n","plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPPd1hNr-gw8"},"source":["# This block converts code into the appropriate shape for visualization.\n","# No changes are required. \n","from sklearn.model_selection import train_test_split\n","n_samples = len(digits.images)\n","data = digits.images.reshape((n_samples, -1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DuOpuRXkAdHp"},"source":["### Part 1: t-SNE \n","First, use t-SNE to reduce the data to 2 dimensions. Plot these data, coloring each point by the true cluster. \n","\n","You can refer to the solution from the dimensionality reduction exercise [here](https://colab.research.google.com/drive/1nTi37NpHcbEPy0-ynqDQtgVJn5NHJ9Km?usp=sharing)"]},{"cell_type":"code","metadata":{"id":"wcuy5vVxQiWl"},"source":["# In this block, add code to use TSNE to reduce the dimensionality of the dataset\n","from sklearn.manifold import TSNE\n","<ADD CODE TO TRANSFORM AND PLOT DATA HERE>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-9puWG3GVsp"},"source":["### Part 2: k-means, no transformation\n","Use k-means (with $k=10$) to find clusters of the data. Visualize the output, by coloring each point from the t-SNE plot with a color corresponding to its cluster assignment.\n","\n","See reference for k-means [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"]},{"cell_type":"code","metadata":{"id":"OzsiO_y7GUU-"},"source":["# Add code to transform data, and to plot the labels on the plot of t-SNE output\n","from sklearn.cluster import KMeans\n","<ADD CODE TO TRANSFORM DATA USING K-MEANS HERE>\n","<ADD CODE TO PLOT DATA HERE>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAawQzwtK5r1"},"source":["### Part 3: k-means, after t-SNE\n","Use t-SNE to reduce the data to 2 dimensions, then use k-means clustering to find clusters of the data. \n","Visualize the cluster labels on the t-SNE dimensionality reduction"]},{"cell_type":"code","metadata":{"id":"kOE5-4HJK-1f"},"source":["# Add code to transform data, and to plot the labels on the plot of t-SNE output\n","from sklearn.cluster import KMeans\n","<ADD CODE TO TRANSFORM DATA USING K-MEANS HERE>\n","<ADD CODE TO PLOT DATA HERE>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"No-_dndsVD-k"},"source":["#### Evaluation: Elbow Plot\n","Produce an elbow plot of the inertia (within cluster sum of squares, $\\displaystyle \\sum_{i=0}^n \\min_{\\mu_j \\in C} (\\| x_i - \\mu_j\\|^2)$) as you increase the number of clusters. \n","\n","What does this approach suggest is a good number of clusters? "]},{"cell_type":"code","metadata":{"id":"Cm5qNrbSRSFP"},"source":["# Fill in code to find and plot inertia for each number of clusters\n","clusters_list = []\n","inertia_list = []\n","for n_clusters in range(4,20):\n","  <ADD CODE TO CLUSTER DATA HERE>\n","  <ADD CODE TO COMPUTE INERTIA HERE>\n","  inertia_list.append(inertia) # append inertia to list\n","  clusters_list.append(n_clusters) # append number of clusters to list\n","plt.plot(clusters_list,inertia_list); # plot dataset \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2efL-AyLVNRf"},"source":["#### Evaluation: Silhouette Plot\n","\n","Produce a silhouette plot for $k = 8, 9, 10, 11, 12$. What does this approach suggest is a good number of clusters? \n","\n","Refer to [this page](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py) for guidance on producing silhouette plots."]},{"cell_type":"code","metadata":{"id":"C2gkZs_CpU6w"},"source":["# The following helper function does not need to be changed; just run this cell\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","import matplotlib.cm as cm\n","def make_silhouette_plot(cluster_labels, sample_silhouette_values, data, plotting_data=None):\n","  \"\"\"\n","  Calculates the silhouette plot of your data, and plots alongside \n","  the cluster labels. \n","  Inputs: cluster_labels (n x 1 array), plotting_data (n x 2) array, data (n x num_features) array\n","  where n=number of data points. \n","  plotting_data will be the data used to plot the data.\n","  data is used to compute the distances for the silhouette score. \n","  \"\"\"\n","  # The following code produces the plots - this should not need to be changed. \n","  if plotting_data is None: plotting_data = data\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  n_clusters = len(np.unique(cluster_labels))\n","  ax1.set_xlim([-0.1, 1])\n","  ax1.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n","  silhouette_avg = np.mean(sample_silhouette_values)\n","  print(\"For n_clusters =\", n_clusters,\n","        \"The average silhouette_score is :\", silhouette_avg)\n","  # Finds the silhouette score for each sample \n","  y_lower = 10\n","  for i in range(n_clusters):\n","    # Aggregate the silhouette scores for samples belonging to\n","    # cluster i, and sort them\n","    ith_cluster_silhouette_values = \\\n","        sample_silhouette_values[cluster_labels == i]\n","\n","    ith_cluster_silhouette_values.sort()\n","\n","    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","    y_upper = y_lower + size_cluster_i\n","\n","    color = cm.nipy_spectral(float(i) / n_clusters)\n","    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n","                      0, ith_cluster_silhouette_values,\n","                      facecolor=color, edgecolor=color, alpha=0.7)\n","    # Label the silhouette plots with their cluster numbers at the middle\n","    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","    # Compute the new y_lower for next plot\n","    y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","  ax1.set_xlabel(\"silhouette coefficient\")\n","  ax1.set_ylabel(\"Cluster label\")\n","\n","  # The vertical line for average silhouette score of all the values\n","  ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","  ax1.set_yticks([])  # Clear the yaxis labels / ticks\n","  ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","  # 2nd Plot showing the actual clusters formed\n","  colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n","  ax2.scatter(plotting_data[:, 0], plotting_data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n","              c=colors, edgecolor='k')\n","  # Labeling the clusters\n","  centers = np.array([np.mean(data[cluster_labels == i,:],axis=0) for i in np.unique(cluster_labels)])\n","  # Draw white circles at cluster centers\n","  ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n","              c=\"white\", alpha=1, s=200, edgecolor='k')\n","\n","  for i, c in enumerate(centers):\n","      ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n","                  s=50, edgecolor='k')\n","\n","  ax2.set_xlabel(\"1st feature space\")\n","  ax2.set_ylabel(\"2nd feature space\")\n","\n","  plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n","                \"with n_clusters = %d\" % n_clusters),\n","                fontsize=14, fontweight='bold')\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lnU6NkQVUax"},"source":["# Here, add code to call the helper function make_silhouette_plot with the appropriate input  function and produce the appropriate plots. \n","range_n_clusters = [8, 9, 10, 11, 12]\n","for n_clusters in range_n_clusters:\n","  <ADD CODE TO COMPUTE CLUSTERS>\n","  make_silhouette_plot(<FILL IN ARGUMENTS>)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgK-mRBnX3ST"},"source":["#### Evaluation: Compare to Actual Labels\n","Here, we compare the produced labels with the actual labels. \n","\n","You cannot expect the label of each cluster to match the true values, so the first step is to transform the cluster labels so that they correspond to the true labels. \n","This function is provided - for each cluster label, it finds the most common true label from those data points. \n","\n","Your task is to find the distance between cluster mappings, as the percentage of target labels that agree with the cluster labels. "]},{"cell_type":"code","metadata":{"id":"1-RmsGtQZyDe"},"source":["# fill in code to find the percentage of target labels that agree with cluster labels\n","# use the provided helper function \n","from scipy import stats\n","def transform_labels(cluster_labels, true_labels):\n","  transform_dict = {}\n","  for n in np.unique(cluster_labels):\n","    target_subset = true_labels[cluster_labels == n]\n","    mode = stats.mode(target_subset)\n","    transform_dict[n] = int(mode.mode)\n","  transformed_data = np.array([transform_dict[target] for target in cluster_labels])\n","  return transformed_data\n","\n","<ADD YOUR CODE TO CALCULATE THE PERCENT OF TARGET LABELS THAT MATCH CLUSTERS>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0RwegrFlXFt"},"source":["### Part 4: k-means after PCA\n","se PCA to reduce the dimensionality to 2 dimensions, then use k-means clustering to find data centers.  Visualize the cluster labels on the t-SNE dimensionality reduction, then  evaluate the model using the above methods. "]},{"cell_type":"code","metadata":{"id":"dciFPFqjlhQx"},"source":["# Add code here to transform data using PCA and find clusters, then to plot the data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bu2a5Ty0mEV8"},"source":["#### Evaluation: Produce Elbow Plot"]},{"cell_type":"code","metadata":{"id":"nuwuMQZdl2Yy"},"source":["# add code to produce an elbow plot of k-means performance \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rE6GJflEmJ6y"},"source":["#### Evaluation: Silhouette Plots"]},{"cell_type":"code","metadata":{"id":"WRoVHtX1mQpz"},"source":["# add code to produce silhouette plots of k-means performance\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpgXJwm7nOWC"},"source":["#### Evaluation: compare to ground truth "]},{"cell_type":"code","metadata":{"id":"Z2o41fDnmWzd"},"source":["# Add code to compare the cluster labels to the ground truth \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9npegQ3inE-T"},"source":["### Part 5: k-means after PCA, 30 components\n","Use PCA to reduce the dimensionality to 30 dimensions, then use k-means clustering to find data centers.  Visualize the cluster labels on the t-SNE dimensionality reduction, then  evaluate the model using the above methods. \n","How does this compare to the 2-dimensional case? What does this suggest about the complexity of the data?"]},{"cell_type":"code","metadata":{"id":"iy0wX6YfnJtQ"},"source":["# Add code to transform data using PCA with 30 components, and plot the output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GM5mnPQVnbxj"},"source":["#### Evaluation: produce elbow plot"]},{"cell_type":"code","metadata":{"id":"Gm7T7FNYnMM4"},"source":["# add code to produce an elbow plot of k-means performance \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85Vp6aGsnfF2"},"source":["#### Evaluation: produce silhouette plot"]},{"cell_type":"code","metadata":{"id":"Nw_jdpAanmxA"},"source":["# add code to produce silhouette plots of k-means performance\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaf3Xd-GnjlX"},"source":["#### Evaluation: compare to ground truth "]},{"cell_type":"code","metadata":{"id":"uEeYs62fn2P8"},"source":["# Add code to compare the cluster labels to the ground truth \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JhpgC6h8tv4j"},"source":["### Optional: Compare with Hierarchical Clustering \n","Use [agglomerative clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) to analyze the data. \n","\n","How many clusters does this suggest? \n","How do the true values from this clustering compare to those from our other methods? "]},{"cell_type":"code","metadata":{"id":"LP5a6tgtuSCX"},"source":["# Add code to compute agglomerative clusters, report the number of clusters, and find the total value \n","from sklearn.cluster import AgglomerativeClustering"],"execution_count":null,"outputs":[]}]}