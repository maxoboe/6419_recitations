{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871f3a7d",
   "metadata": {},
   "source": [
    "A quick intro to Google Colab - we'll be using this to run jupyter notebooks in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded46cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ffca7",
   "metadata": {},
   "source": [
    "See detailed introductions at: \n",
    "https://colab.research.google.com/\n",
    "\n",
    "Some of the most useful features for our class: \n",
    "- linear algebra\n",
    "    - Recommended reference: https://cheatsheets.quantecon.org/\n",
    "- data management\n",
    "    - pandas \n",
    "- plotting \n",
    "    - Recommended libraries: Seaborn, matplotlib\n",
    "- statistics packages \n",
    "    - scipy.stats: test statistics, reference distributions\n",
    "    - statsmodels: classical statistics, e.g. regression, ANOVA\n",
    "    - scikit-learn: statistical learning software, for clustering, classification, regression, etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e8bf9",
   "metadata": {},
   "source": [
    "# Exercise: Exponential Hypothesis Testing\n",
    "A firm produces engine parts that wear out over time. \n",
    "The lifetime of an engine part can be modeled by an exponential distribution; that is, for average lifetime of the part $\\lambda$, the probability density of lifetime $x$ is: $f(x; \\lambda) = \\begin{cases} \\lambda e^{- \\lambda x} \\qquad & x \\geq 0 \\\\ 0 & \\text{ else} \\end{cases}$. \n",
    "The firm has developed a new model, has conducted tests to find the lifetimes of the new parts, and wants you to determine if the new part is a significant improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10459d60",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "First, find the maximum likelihood estimator for the parameter $\\lambda$. Use this parameter to find the MLE for distributions of the files `old_part.csv` and `new_part.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd7fb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda for old part: 0.3321527061334148, lambda for new part: 0.25159196418944174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1234)\n",
    "X_old_part = np.random.exponential(scale=3, size=100)\n",
    "X_new_part = np.random.exponential(scale=3.5, size=100)\n",
    "pd.DataFrame(X_old_part,columns=['lifetime']).to_csv('old_part.csv',index=False)\n",
    "pd.DataFrame(X_new_part,columns=['lifetime']).to_csv('new_part.csv',index=False)\n",
    "\n",
    "\n",
    "# path_base = 'https://raw.githubusercontent.com/maxoboe/6419_recitations/main/R1/'\n",
    "# X_old_part = pd.read_csv(path_base + 'old_part.csv').values\n",
    "# X_new_part = pd.read_csv(path_base + 'new_part.csv').values\n",
    "\n",
    "lambda_old = 1 / np.mean(X_old_part)\n",
    "lambda_new = 1 / np.mean(X_new_part)\n",
    "print(\"Lambda for old part: {}, lambda for new part: {}\".format(lambda_old, lambda_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea098f7",
   "metadata": {},
   "source": [
    "### Part 2: \n",
    "Write down a null hypothesis and alternate hypothesis for the question of whether the new part lasts longer than the old part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca9028",
   "metadata": {},
   "source": [
    "$\\lambda = 1 / \\mu$\n",
    "\n",
    "$H_0$: $\\mu_{new} = \\mu_{old}$\n",
    "\n",
    "$H_A$: $\\mu_{new} > \\mu_{old}$\n",
    "\n",
    "$H_A$: $\\lambda_{new} < \\lambda_{old}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e8c6f",
   "metadata": {},
   "source": [
    "### Part 3: \n",
    "Evaluate a likelihood ratio test to evaluate the specified null hypothesis. Find the value of the test, and the appropriate parameter for the corresponding $\\chi^2$ distribution.\n",
    "\n",
    "A helper function is provided that finds the likelihood of one observation given a parameter guess. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e909bd",
   "metadata": {},
   "source": [
    "Likelihood ratio: $\\displaystyle -2 \\log\\left(\\frac{\\sup_{\\lambda \\in \\Theta_0} \\mathcal{L}(X | \\lambda)}{\\sup_{\\lambda \\in \\Theta} \\mathcal{L}(X | \\lambda)} \\right)$ \n",
    "\n",
    "Likelihood ratio: $\\Lambda = \\displaystyle -2 \\log\\left(\\frac{\\sup_{\\lambda \\in \\Theta_0} \\mathcal{L}(X_{old} | \\lambda) \\mathcal{L}(X_{new} | \\lambda)}{\\sup_{\\lambda_1 \\in \\Theta} \\mathcal{L}(X_{old} | \\lambda_1)\\sup_{\\lambda_2 \\in \\Theta} \\mathcal{L}(X_{new} | \\lambda_2)} \\right)$ \n",
    "\n",
    "What we found before: $\\hat{\\lambda}_{old} = \\sup_{\\lambda \\in \\Theta_0} \\mathcal{L}(X_{old} | \\lambda)$\n",
    "\n",
    "MLE in $H_0$: $\\hat{\\lambda}_{new} = \\hat{\\lambda}_{old}$\n",
    "\n",
    "MLE overall: from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4c92fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw likelihood ratio is 0.14617379707091524\n"
     ]
    }
   ],
   "source": [
    "def likelihood(X, param):\n",
    "    def indiv_likelihood(x):\n",
    "        if x < 0: return 0\n",
    "        return param * np.exp(-param * x)\n",
    "    return np.prod([indiv_likelihood(x) for x in X])\n",
    "numerator_lambda = 1 / np.mean(np.hstack([X_old_part,X_new_part]))\n",
    "numerator = likelihood(X_old_part, numerator_lambda) * likelihood(X_new_part, numerator_lambda)\n",
    "denomenator = likelihood(X_old_part, lambda_old) * likelihood(X_new_part, lambda_new)\n",
    "\n",
    "print(\"The raw likelihood ratio is {}\".format(numerator / denomenator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa399c8",
   "metadata": {},
   "source": [
    "### Part 4:\n",
    "At a significance level of $\\alpha = 0.05$, do you reject the null hypothesis? \n",
    "\n",
    "\n",
    "Hint: use the package `scipy.stats` and and refer to [this link](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cbbf6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test value is 3.8459179486611847, which has p value of 0.04986721783570636\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2 \n",
    "test_value = -2 * np.log(numerator / denomenator)\n",
    "dof = 1 \n",
    "p_value = 1 - chi2.cdf(test_value, dof)\n",
    "print(\"Test value is {}, which has p value of {}\".format(test_value,p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075f1ee",
   "metadata": {},
   "source": [
    "### Part 5: \n",
    "Now consider some alternate tests. For each, find the desired test statistic and discuss the result. \n",
    "\n",
    "Hint: use the package `scipy.stats` and and refer to [this link](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) for reference. \n",
    "\n",
    "1. Assuming that durations are normally distributed, evaluate a test for the hypothesis that the two distributions have the same mean. \n",
    "2. Without making any distributional assumptions, test the hypothesis that the two distributions have the same mean.\n",
    "3. Test the hypothesis that the two distributions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5f42e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Ttest_indResult(statistic=-2.0670154517829284, pvalue=0.04003346528145235)\n",
      "Test 2: RanksumsResult(statistic=-1.5271180544538152, pvalue=0.1267316582174145)\n",
      "Test 3: KstestResult(statistic=0.17, pvalue=0.11119526053829192)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "test1 = stats.ttest_ind(X_old_part, X_new_part)\n",
    "test2 = stats.ranksums(X_old_part,X_new_part)\n",
    "test3 = stats.ks_2samp(X_old_part,X_new_part)\n",
    "print(\"Test 1: {}\".format(test1))\n",
    "print(\"Test 2: {}\".format(test2))\n",
    "print(\"Test 3: {}\".format(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c8af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
