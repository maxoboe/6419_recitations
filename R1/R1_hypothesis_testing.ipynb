{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871f3a7d",
   "metadata": {},
   "source": [
    "A quick intro to Google Colab - we'll be using this to run jupyter notebooks in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded46cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ffca7",
   "metadata": {},
   "source": [
    "See detailed introductions at: \n",
    "https://colab.research.google.com/\n",
    "\n",
    "Some of the most useful features for our class: \n",
    "- linear algebra\n",
    "    - Recommended reference: https://cheatsheets.quantecon.org/\n",
    "- data management\n",
    "    - pandas \n",
    "- plotting \n",
    "    - Recommended libraries: Seaborn, matplotlib\n",
    "- statistics packages \n",
    "    - scipy.stats: test statistics, reference distributions\n",
    "    - statsmodels: classical statistics, e.g. regression, ANOVA\n",
    "    - scikit-learn: statistical learning software, for clustering, classification, regression, etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e8bf9",
   "metadata": {},
   "source": [
    "# Exercise: Exponential Hypothesis Testing\n",
    "A firm produces engine parts that wear out over time. \n",
    "The lifetime of an engine part can be modeled by an exponential distribution; that is, for average lifetime of the part $\\lambda$, the probability density of lifetime $x$ is: $f(x; \\lambda) = \\begin{cases} \\lambda e^{- \\lambda x} \\qquad & x \\geq 0 \\\\ 0 & \\text{ else} \\end{cases}$. \n",
    "The firm has developed a new model, has conducted tests to find the lifetimes of the new parts, and wants you to determine if the new part is a significant improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10459d60",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "First, find the maximum likelihood estimator for the parameter $\\lambda$. Use this parameter to find the MLE for distributions of the files `old_part.csv` and `new_part.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "path_base = 'https://raw.githubusercontent.com/maxoboe/6419_recitations/main/R1/'\n",
    "X_old_part = pd.read_csv(path_base + 'old_part.csv').values.reshape(-1,)\n",
    "X_new_part = pd.read_csv(path_base + 'new_part.csv').values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea098f7",
   "metadata": {},
   "source": [
    "### Part 2: \n",
    "Write down a null hypothesis and alternate hypothesis for the question of whether the new part lasts longer than the old part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d26a01",
   "metadata": {},
   "source": [
    "$H_0$: \n",
    "\n",
    "$H_A$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e8c6f",
   "metadata": {},
   "source": [
    "### Part 3: \n",
    "Evaluate a likelihood ratio test to evaluate the specified null hypothesis. Find the value of the test, and the appropriate parameter for the corresponding $\\chi^2$ distribution.\n",
    "\n",
    "A helper function is provided that finds the likelihood of a vector of data given a parameter guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c92fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X, param):\n",
    "    def indiv_likelihood(x):\n",
    "        if x < 0: return 0\n",
    "        return param * np.exp(-param * x)\n",
    "    return np.prod([indiv_likelihood(x) for x in X])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa399c8",
   "metadata": {},
   "source": [
    "### Part 4:\n",
    "At a significance level of $\\alpha = 0.05$, do you reject the null hypothesis? \n",
    "(assume the sample size is large enough that you can apply Wilks' theorem)\n",
    "Hint: use the package `scipy.stats` and and refer to [this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html) to find the CDF of the chi squared distribution. \n",
    "\n",
    "Alternately, use an online lookup table like [this](https://www.socscistatistics.com/pvalues/chidistribution.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075f1ee",
   "metadata": {},
   "source": [
    "### Part 5: \n",
    "Now consider some alternate tests. For each, find the desired test statistic and discuss the result. \n",
    "\n",
    "Hint: use the package `scipy.stats` and and refer to [this link](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) for reference. \n",
    "\n",
    "1. Assuming that durations are normally distributed, evaluate a test for the hypothesis that the two distributions have the same mean. \n",
    "2. Without making any distributional assumptions, test the hypothesis that the two distributions have the same mean.\n",
    "3. Test the hypothesis that the two distributions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f42e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
